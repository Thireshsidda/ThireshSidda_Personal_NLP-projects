{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NameEnitityRecognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdGVqprbbJ-g"
      },
      "source": [
        "# Named Entity Recognition with Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3GQ3nlZWclJL",
        "outputId": "e44a018b-3854-42b5-a79e-ad894661c48f"
      },
      "source": [
        "#Loading the data to variable data using pandas library.\n",
        "import pandas as pd\n",
        "data=pd.read_csv(\"ner_dataset.csv\",encoding= 'unicode_escape')\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0   Sentence #           Word  POS Tag\n",
              "0           0  Sentence: 1      Thousands  NNS   O\n",
              "1           1          NaN             of   IN   O\n",
              "2           2          NaN  demonstrators  NNS   O\n",
              "3           3          NaN           have  VBP   O\n",
              "4           4          NaN        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojPYJ727cxCE"
      },
      "source": [
        "#Creating a function to make filter the token and tag data\n",
        "#importing itertools library\n",
        "from itertools import chain\n",
        "def make_dict_map(data, tokentag):\n",
        "    token_to_idx = {}\n",
        "    idx_to_token = {}\n",
        "    #Checking for tokentag to filter   \n",
        "    if tokentag == 'token':\n",
        "        voc = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        voc = list(set(data['Tag'].to_list()))\n",
        "    #Creating dictionary for idx_to_token and token_to_idx\n",
        "    idx_to_token = {idx:tok for  idx, tok in enumerate(voc)}\n",
        "    token_to_idx = {tok:idx for  idx, tok in enumerate(voc)}\n",
        "    return token_to_idx , idx_to_token\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y74ZNshzsBiG"
      },
      "source": [
        "#Filtering the token and tag using make_dict_map function\n",
        "token_to_idx, idx_to_token = make_dict_map(data, 'token')\n",
        "tag_to_idx, idx_to_tag = make_dict_map(data, 'tag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aJnRcKzeIqp"
      },
      "source": [
        "#mapping the data with token and tag\n",
        "data['Word_idx'] = data['Word'].map(token_to_idx)\n",
        "data['Tag_idx'] = data['Tag'].map(tag_to_idx)\n",
        "#Filling the Nan values in the dataset\n",
        "data_fillna = data.fillna(method='ffill', axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tvMxr6B65ii",
        "outputId": "ac8c74b8-5581-4577-f3fd-8a71422dbc3d"
      },
      "source": [
        "# Groupby and collect columns\n",
        "data_group = data_fillna.groupby(['Sentence #'],as_index=False)['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx'].agg(lambda x: list(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "NETe3oCz7r0Z",
        "outputId": "5844ca20-32b7-4502-d71c-74ace86ef75c"
      },
      "source": [
        "data_group.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
              "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
              "      <td>[5502, 11708, 21765, 11882, 32261, 5802, 8324,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 10</td>\n",
              "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
              "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
              "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[20212, 25622, 28373, 24041, 26422, 20972, 985...</td>\n",
              "      <td>[4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 100</td>\n",
              "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
              "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
              "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
              "      <td>[2716, 18388, 20420, 317, 7998, 14489, 10501, ...</td>\n",
              "      <td>[1, 1, 13, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1000</td>\n",
              "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
              "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[31635, 33329, 33524, 5151, 10982, 28374, 4328...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 10000</td>\n",
              "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
              "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
              "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
              "      <td>[6680, 8691, 32921, 22007, 14800, 14275, 19174...</td>\n",
              "      <td>[0, 1, 1, 12, 2, 1, 13, 1, 0, 1, 4, 1, 4, 1, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #  ...                                            Tag_idx\n",
              "0      Sentence: 1  ...  [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, ...\n",
              "1     Sentence: 10  ...  [4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "2    Sentence: 100  ...  [1, 1, 13, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 14...\n",
              "3   Sentence: 1000  ...                  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
              "4  Sentence: 10000  ...  [0, 1, 1, 12, 2, 1, 13, 1, 0, 1, 4, 1, 4, 1, 1...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5guDSqlm8G5Z"
      },
      "source": [
        "#Importing train_test_split to split the training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Importing libraries from keras\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rHOJ8R6eKH7"
      },
      "source": [
        "#Function to extract train_tokens, test_tokens, val_tokens, train_tags,test_tags,val_tags\n",
        "\n",
        "def get_train_test_val(data_group, datas):\n",
        "\n",
        "    #Creating pad_tokens (X var)    \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    #getting the maximum token length and tag length\n",
        "    ntoken = len(list(set(datas['Word'].to_list())))\n",
        "    ntag = len(list(set(datas['Tag'].to_list())))\n",
        "    \n",
        "    padtokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= ntoken - 1)\n",
        "    #Creating Pad Tags (y var) and converting into one hot encoding\n",
        "    tags = data_group['Tag_idx'].tolist()\n",
        "    padtags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag_to_idx[\"O\"])\n",
        "    ntags = len(tag_to_idx)\n",
        "    padtags = [to_categorical(i, num_classes=ntags) for i in padtags]\n",
        "    \n",
        "    #Splitting the train, test and validation set\n",
        "    tokens, testtokens, tags, testtags = train_test_split(padtokens, padtags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    traintokens, valtokens, traintags, valtags = train_test_split(tokens,tags,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'length of train tokens :', len(train_tokens),\n",
        "        '\\nlength of train tags   :', len(train_tags),\n",
        "        '\\nlength of test tokens  :', len(test_tokens),\n",
        "        '\\nlength of test tags    :', len(test_tags),\n",
        "        '\\nlength of val tokens   :', len(val_tokens),\n",
        "        '\\nlength of val tags     :', len(val_tags),\n",
        "    )\n",
        "    \n",
        "    return traintokens, testtokens, valtokens, traintags,testtags,valtags\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTnXOPA--ctH",
        "outputId": "b1becd27-f15b-4202-a689-55dc20abf2b6"
      },
      "source": [
        "#printing the lengths of train_tokens, test_tokens, val_tokens, train_tags,test_tags,val_tags\n",
        "traintokens, testtokens, valtokens, traintags,testtags,valtags= get_train_test_val(data_group, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train tokens : 32372 \n",
            "length of train tags   : 32372 \n",
            "length of test tokens  : 4796 \n",
            "length of test tags    : 4796 \n",
            "length of val tokens   : 10791 \n",
            "length of val tags     : 10791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvkuSczWikRQ"
      },
      "source": [
        "#Importing numpy library and tensorflow.keras library for model building.\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tensorflow.random.set_seed(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdoSRoMninws"
      },
      "source": [
        "#Finding the input and output dimension for Data\n",
        "input_dim = len(list(set(data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0US9_kewJNim",
        "outputId": "98d92884-cf5b-45e4-af75-3b4f03c75369"
      },
      "source": [
        "#Finding the length of tag_to_idx and saving in ntags variable\n",
        "ntags = len(tag_to_idx)\n",
        "ntags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Xc8wGfklFG"
      },
      "source": [
        "#Function for the architecture of model.\n",
        "def get_bilstmlstm():\n",
        "    #selecting Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Adding Embedding layer to the model\n",
        "    model.add(Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length))\n",
        "\n",
        "    # Adding bidirectional LSTM to the model\n",
        "    model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
        "\n",
        "    # Adding LSTM to the model\n",
        "    model.add(LSTM(units=output_dim, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
        "\n",
        "    # Adding timeDistributed Layer to the model\n",
        "    model.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\n",
        "\n",
        "    #Adding Adam optimizer to the model\n",
        "    # Compile model\n",
        "    #Adding Adam optimizer to the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlvkeQjQkvjC"
      },
      "source": [
        "#Function to find the loss of the model\n",
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(25):\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ynmGIxkzuU",
        "outputId": "7429bc45-3d3d-49ba-cdcc-1e2aa5d33b03"
      },
      "source": [
        "#The Final output will be obtained after the 25 epochs as we set the loop to run 25 times\n",
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstmlstm()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 104, 64)           2251456   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 104, 128)          66048     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 104, 64)           49408     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 104, 17)           1105      \n",
            "=================================================================\n",
            "Total params: 2,368,017\n",
            "Trainable params: 2,368,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "26/26 [==============================] - 151s 6s/step - loss: nan - accuracy: 0.0083 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 138s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 136s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 144s 6s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 141s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 144s 6s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 145s 6s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 142s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 142s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 143s 6s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 141s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 139s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n",
            "26/26 [==============================] - 140s 5s/step - loss: nan - accuracy: 0.0076 - val_loss: nan - val_accuracy: 0.0074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26oAg3dxOh2d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ4YVI2POi_f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}