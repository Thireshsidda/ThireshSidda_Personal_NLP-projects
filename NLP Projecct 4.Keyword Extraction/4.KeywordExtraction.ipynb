{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.KeywordExtraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu4zych0czQ4"
      },
      "source": [
        "#Keyword Extraction with Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KJ3V4uCrV4q"
      },
      "source": [
        "#Loading the datset\n",
        "#Importing pandas library\n",
        "import pandas as pd \n",
        "df=pd.read_csv('papers.csv',engine='c', error_bad_lines=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "1pImPvf9sK0a",
        "outputId": "a3c8163b-9a3b-4347-9bb1-4bd4d9d2534c"
      },
      "source": [
        "#Data stored in variable df\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>994</td>\n",
              "      <td>1994</td>\n",
              "      <td>Single Transistor Learning Synapses</td>\n",
              "      <td>NaN</td>\n",
              "      <td>994-single-transistor-learning-synapses.pdf</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Single Transistor Learning Synapses\\n\\nPaul Ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7237</th>\n",
              "      <td>996</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bias, Variance and the Combination of Least Sq...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>996-bias-variance-and-the-combination-of-least...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bias, Variance and the Combination of\\nLeast S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7238</th>\n",
              "      <td>997</td>\n",
              "      <td>1994</td>\n",
              "      <td>A Real Time Clustering CMOS Neural Engine</td>\n",
              "      <td>NaN</td>\n",
              "      <td>997-a-real-time-clustering-cmos-neural-engine.pdf</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>A Real Time Clustering CMOS\\nNeural Engine\\nT....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>998</td>\n",
              "      <td>1994</td>\n",
              "      <td>Learning direction in global motion: two class...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>998-learning-direction-in-global-motion-two-cl...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Learning direction in global motion: two\\nclas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7240</th>\n",
              "      <td>999</td>\n",
              "      <td>1994</td>\n",
              "      <td>Correlation and Interpolation Networks for Rea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>999-correlation-and-interpolation-networks-for...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Correlation and Interpolation Networks for\\nRe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7241 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                         paper_text\n",
              "0        1  ...  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
              "1       10  ...  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
              "2      100  ...  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
              "3     1000  ...  Bayesian Query Construction for Neural\\nNetwor...\n",
              "4     1001  ...  Neural Network Ensembles, Cross\\nValidation, a...\n",
              "...    ...  ...                                                ...\n",
              "7236   994  ...  Single Transistor Learning Synapses\\n\\nPaul Ha...\n",
              "7237   996  ...  Bias, Variance and the Combination of\\nLeast S...\n",
              "7238   997  ...  A Real Time Clustering CMOS\\nNeural Engine\\nT....\n",
              "7239   998  ...  Learning direction in global motion: two\\nclas...\n",
              "7240   999  ...  Correlation and Interpolation Networks for\\nRe...\n",
              "\n",
              "[7241 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pxs0rWTtzA-",
        "outputId": "4a346ced-8945-4e6f-a8f7-a745193585db"
      },
      "source": [
        "#Importing the modules from libraries nltk and re\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huSyuo5WOwuz"
      },
      "source": [
        "#Listing of custom stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "new_words = [\"fig\",\"figure\",\"image\",\"sample\",\"using\",\"show\", \"result\", \"large\", \"one\", \"two\", \"three\",\"four\", \"five\", \"seven\",\"eight\",\"nine\",\"also\"]\n",
        "stop_words = list(stop_words.union(new_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svifz8iaPb-Y",
        "outputId": "8b73e7c7-dbf0-4cad-8f8a-1e85ac0ffd9e"
      },
      "source": [
        "print(stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['here', 'between', 's', 'i', 'am', 'won', 'out', 'he', 'did', 't', \"doesn't\", 'sample', 'two', 'at', \"you'll\", 'very', 'she', 'didn', 'doing', 'couldn', 'with', 'again', 'eight', 'her', 'o', 'hasn', 'seven', \"aren't\", 'of', 'that', 'itself', 'four', 'few', 've', 'does', 'should', \"mustn't\", 'they', 'doesn', 'was', 'after', 'why', 'these', 'own', 'same', 'an', 'ma', \"should've\", 'not', 'such', 'herself', 'about', 'hadn', 'haven', 'our', 'if', 'y', 'under', 'having', \"it's\", 'below', 'had', 'mightn', 'from', \"wasn't\", 'in', 'ours', 'and', 'how', 'has', 'on', 'show', 'so', 'it', 'above', 'their', 'this', 'have', 'too', 'all', \"that'll\", 'are', 'both', 'ourselves', 'only', 'through', 'or', \"haven't\", 'themselves', 'image', 'up', 'fig', 'where', 'shan', 'be', 'any', \"needn't\", 'do', 'further', 'some', 'what', 'against', 'to', 'nor', 'down', 'wasn', 'yourself', \"hasn't\", 'your', 'once', 'd', 'm', 'three', \"she's\", 'him', 'result', 'because', 'by', 'myself', 'while', 'off', 'just', 'weren', \"wouldn't\", 'into', 'were', 'over', 'also', 'one', 'aren', 'you', \"don't\", 'me', 'ain', 'wouldn', \"you'd\", 'don', 'other', 'figure', 'then', \"you've\", 'we', \"couldn't\", 'each', 'no', 'them', 'there', \"weren't\", 'more', 'using', 'his', 'as', 'the', 'theirs', 'yourselves', \"isn't\", 'before', 'its', 'hers', 'my', 'than', 'a', 'been', 'nine', 'until', 'five', 'which', \"won't\", 'yours', 'during', 'now', 'being', \"mightn't\", 'those', 'but', 'who', 'for', 'when', 'mustn', 'isn', \"shouldn't\", 'most', 'can', 'himself', 'large', \"you're\", 'will', 'is', 'shouldn', \"shan't\", \"didn't\", 'll', 'needn', 'whom', 're', \"hadn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr6aZxDVyb4a"
      },
      "source": [
        "#Defining a function to preprocess the text.\n",
        "def preprocessor(text):\n",
        "    # converting text into lowercase\n",
        "    text=text.lower()\n",
        "    #removing the tags present in the text\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    # removing tje special characters and digits in the text\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text) \n",
        "    #Converting to list of words from string\n",
        "    text = text.split()\n",
        "    # removing the stopwords present in the text\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "    # removing the words less than three letters\n",
        "    text = [word for word in text if len(word) >= 3]\n",
        "    #Lemmatize each words using WordNetLemmatizer function\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    text = [lmtzr.lemmatize(word) for word in text]\n",
        "    return ' '.join(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOGoIAGwd5Ug",
        "outputId": "21ca2ee3-ee88-42f8-dba4-7df83817b482"
      },
      "source": [
        "#Applying the preprocessor function to the text\n",
        "documents = df['paper_text'].apply(lambda x:preprocessor(x))\n",
        "documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       self organization associative database applica...\n",
              "1       mean field theory layer visual cortex applicat...\n",
              "2       storing covariance associative long term poten...\n",
              "3       bayesian query construction neural network mod...\n",
              "4       neural network ensemble cross validation activ...\n",
              "                              ...                        \n",
              "7236    single transistor learning synapsis paul hasle...\n",
              "7237    bias variance combination least square estimat...\n",
              "7238    real time clustering cmos neural engine serran...\n",
              "7239    learning direction global motion class psychop...\n",
              "7240    correlation interpolation network real time ex...\n",
              "Name: paper_text, Length: 7241, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDBmauP134LU"
      },
      "source": [
        "#Importing countVectorizer from sklearn library\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#Creating the vocabulary from the words\n",
        "countvector=CountVectorizer(max_df=0.95,max_features=10000,ngram_range=(1,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7jGzuDjlcZT"
      },
      "source": [
        "#Scaling the data\n",
        "wcvector=countvector.fit_transform(documents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHyUAQlXDuN_",
        "outputId": "14d274e1-4564-4128-d9af-30cf7a772e4f"
      },
      "source": [
        "#Importing TfidTransformer module from sklearn library\n",
        "#Calculating the reverse frequency of documents.\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "transformer.fit(wcvector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFMLYKAkwRPg"
      },
      "source": [
        "#Defining function to get the feature names and tf-idf score of top n items\n",
        "def extractVector(featurenames, sorteditems, top=10):\n",
        "    #using only top items \n",
        "    sorteditems = sorteditems[:top]\n",
        "    scorevals = []\n",
        "    featurevals = []\n",
        "    for idx, score in sorteditems:\n",
        "        fname = featurenames[idx]\n",
        "        #feature name and corresponding score\n",
        "        scorevals.append(round(score, 3))\n",
        "        featurevals.append(featurenames[idx])\n",
        "\n",
        "    #creating a tuple of feature and score\n",
        "    results= {}\n",
        "    for idx in range(len(featurevals)):\n",
        "        results[featurevals[idx]]=scorevals[idx]  \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaSMX9OgwO7h"
      },
      "source": [
        "#defining a function to return tuples of columns and data\n",
        "def sortedcoo(matrix):\n",
        "    tuples = zip(matrix.col, matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "# getting the feature name.\n",
        "feature_names=countvector.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lguN_Lr-waj0"
      },
      "source": [
        "#Defining a function to get keywords.\n",
        "def getKeywords(id, doc):\n",
        "    #generating the tf_idf for documents\n",
        "    tfidfvector=transformer.transform(cv.transform([doc[id]]))\n",
        "    #Sorting the vectors in descending order\n",
        "    sorteditems=sortedcoo(tfidfvector.tocoo())\n",
        "    #Extracting the top n values\n",
        "    keywords=extractVector(feature_names,sorteditems,10)\n",
        "    return keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_GAboaQBYS-"
      },
      "source": [
        "#Defining function to print the results.\n",
        "def printResults(id,keyword, df):\n",
        "    # now print the results\n",
        "    print(\"\\n=====Title=====\")\n",
        "    print(df['title'][id])\n",
        "    print(\"\\n=====Abstract=====\")\n",
        "    print(df['abstract'][id])\n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keyword:\n",
        "        print(k,keyword[k])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lic_e5cVD2mW",
        "outputId": "1b35663b-bcb2-41b9-b7e5-9ffc7692ebe4"
      },
      "source": [
        "#Output We are getting from keywords and printResults function.\n",
        "id=941\n",
        "keywords=getKeywords(id, docs)\n",
        "printResults(id,keywords, df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "=====Title=====\n",
            "Algorithms for Non-negative Matrix Factorization\n",
            "\n",
            "=====Abstract=====\n",
            "Non-negative matrix factorization (NMF) has previously been shown to \r\n",
            "be a useful decomposition for multivariate data. Two different multi- \r\n",
            "plicative algorithms for NMF are analyzed. They differ only slightly in \r\n",
            "the multiplicative factor used in the update rules. One algorithm can be \r\n",
            "shown to minimize the conventional least squares error while the other \r\n",
            "minimizes the generalized Kullback-Leibler divergence. The monotonic \r\n",
            "convergence of both algorithms can be proven using an auxiliary func- \r\n",
            "tion analogous to that used for proving convergence of the Expectation- \r\n",
            "Maximization algorithm. The algorithms can also be interpreted as diag- \r\n",
            "onally rescaled gradient descent, where the rescaling factor is optimally \r\n",
            "chosen to ensure convergence. \n",
            "\n",
            "===Keywords===\n",
            "update rule 0.344\n",
            "update 0.285\n",
            "auxiliary 0.212\n",
            "non negative matrix 0.21\n",
            "negative matrix 0.209\n",
            "rule 0.192\n",
            "nmf 0.183\n",
            "multiplicative 0.175\n",
            "matrix factorization 0.163\n",
            "matrix 0.163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VASAfOwqtore"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}